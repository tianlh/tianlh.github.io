---
layout: post
title: "卷积神经网络（二）：使用keras + tensorflow构造CNN进行训练"
date: 2020-10-11
author: Tianlh
header-img: "img/head-bg1.jpg"
tags:
  - 卷积神经网络
  - CNN
  - 深度学习
  - keras
  - tensorflow
---

#### **相关库**

##### **scikit-learn**
- scikit-learn是一个通用的机器学习库，提供很多传统机器学习的实现，并且高度封装，用户可以很便捷的使用。另外，由于传统的机器学习方法注重特征的提取，因此scikit-learn提供了强大的特征工程相关函数。
- <https://scikit-learn.org/stable/tutorial/machine_learning_map/>
- ![image]({{ "/img/post/fhsksjkgb3r9083402rhrk0erewu9e89fdsjk.png" }})

##### **tensorflow**
- tensorflow是一个深度学习库，它的自由度很高。并且由于深度学习算法本身就是一个特征学习的过程，因此不需要人工进行特征提取，tensorflow也就没有提供太多专门提取特征的函数。

##### **theano**
- theano与tensorflow类似，也是一个深度学习库。

##### **keras**
- keras是基于python的神经网络库，实现了对tensorflow和theano的封装，借助keras可以方便的搭建网络模型。

#### **环境配置**
- 配置的时候注意python版本和tensorflow版本需要匹配，我用的python 3.6-64搭配tensorflow 2.x。
- tensorflow 2.x 和 1.x 整个架构都不一样了，注意选择版本。tensorflow 1.x 使用静态图模式，性能比较占优势，但是debug不方便。tensorflow 2.x 使用动态图模式，这种形式和 python 执行比较接近，语句按顺序执行，也比较好上手。
- CPU版本使用pip一键安装（pip install tensorflow）。
- 不能直接连外网就比较麻烦，只能手动安装，去https://pypi.org/上自己下载tensorflow和依赖库的安装包，一个个手动安装。<br/>
安装包一般是.whl或者压缩包。如果是.whl格式，使用```pip install xxx.whl```命令安装。<br/>
如果是压缩包，解压后会有setup.py文件，执行命令安装<br/>
```python setup.py build```<br/>
```python setup.py install```
- GPU版本安装还需要额外配置环境

#### **模型训练**

##### **数据预处理**
- 数据采集打标签，采集的数据可以以.csv格式保存。
- 加载数据，划分训练集和测试集<br/>
```python
import pandas as pd
import tensorflow as tf 
data = pd.read_csv(path_name)
```
// 输入数据为1 * w的数据，一共M组数据， M * N <br/>
// 最后一列为label
```python
col = data.shape[1] - 1
dataTrain, dataTest, labelTrain, labelTest = train_test_split(data[data.columns[0:col]].values, data['label'].values, test_size = 0.3, random_state = 0)
```
// 转化格式<br/>
// 以conv2D为例，默认input_shape为channels_last，即数据以[batch
, height, width, channels]的排列顺序
```python
xTrain = tf.reshape(dataTrain, [dataTrain.shape[0], 1, ])
```
label一般需要处理一下，比如转换成使用one-hot编码的形式

##### **利用keras构建模型**
```python
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape, Droput
def CNN()
    model = mode.sequential()
```
// 添加网络层
// 可以加些预处理，如reshape操作
// 卷积层：depth为64，kernel_size为1 * 3， 激活函数为relu，填充（padding）方式为same（这样输出数据的长宽保持不变），这样input_shape = [b，1，w, 1]，output_shape = [b，1, w, 64]
```python
    model.add(Conv2D(64, (1, 3), activation = 'relu', padding = 'same))
```
// 再加一层卷积层，input_shape = [b，1, w, 64]，output_shape = [b，1, w, 64]
```python
    model.add(Conv2D(64, (1, 3), activation = 'relu', padding = 'same))
```
// 池化层，pool_size为1 * 2，outpue_shape = [b, 1, w / 2, 64]
```python
    model.add(MaxPooling2D((1,2)))
```
// 拉平
```python
    model.add(Flatten())
```
// 丢弃一些数据防止过拟合
```python
    model.add(Dropout(0.4))
```
// 全连接层
```python
    model.add(Dense(32, activation = 'softmax'))
    return model

model = CNN()
model.summary()
```

##### **训练**
// 转换数据格式，与model一致
```python
dTrain = tf.reshape(dataTrain, [dataTrian.shape[0], 1, dataTrain.shape[1], 1])
```
// labelTrain2采用ont-hot编码，比如三种标签，标签1转化为[0,0,1]，标签2转化为[0,1,0]，标签3转化为[1,0,0]
lTrain = tf.reshape(labelTrian2, [-1, 3])
// 设置训练器，损失函数，准确率评估方法
```python
model.compile(optimizer = 优化器, loss = 损失函数, metrics = ["准确率评估方法”])
```
// 训练，迭代75次，每次使用512个样本
```python
fit = model.fit(dTrain, lTrain, batch_size = 512, epochs = 75)
```
// 测试训练结果
```python
loss_acc = model.evaluate(xTest, yTest)
```

##### **模型保存**
```python
model.save("XXX.h5")
```
默认的模型格式为.h5，为了工程化，我对模型做了一些简化，导出成json，b方便后续准换成C数据结构
